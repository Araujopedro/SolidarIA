# SolidarIA - Sistema Completo Unificado
# Marketplace Inteligente de Doa√ß√µes com IoT + ML + An√°lise Explorat√≥ria
# Vers√£o Final Consolidada para Tese

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

# ML Libraries
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, mean_absolute_error, r2_score
import joblib
import os
import json

warnings.filterwarnings('ignore')

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)

class SolidarIAComplete:
    """
    ü§ñ SolidarIA - Sistema Completo Unificado
    
    Marketplace Inteligente de Doa√ß√µes com:
    - An√°lise Explorat√≥ria Avan√ßada
    - Machine Learning para Predi√ß√µes
    - Visualiza√ß√µes Interativas
    - Mapa Geogr√°fico do Brasil
    - Dashboard Completo
    """

    def __init__(self):
        self.ml_models = {}
        self.encoders = {}
        self.scalers = {}
        self.feature_names = []
        self.dataset_info = {}
        self.df = None

    def executar_sistema_completo(self, dataset_path: str = None):
        """Executa o sistema SolidarIA completo"""
        
        print("üåü SISTEMA SOLIDARIA COMPLETO - VERS√ÉO UNIFICADA")
        print("ü§ñ IA Descobrindo Padr√µes para Otimizar Doa√ß√µes")
        print("="*70)

        try:
            # 1. Carregar dados
            if dataset_path and os.path.exists(dataset_path):
                self.df = self.carregar_dados_reais(dataset_path)
            else:
                print("üìä Gerando dados sint√©ticos para demonstra√ß√£o...")
                self.df = self.criar_dados_sinteticos_completos()

            # 2. Preparar dados
            self.df = self.preparar_dados_completos()

            # 3. An√°lise Explorat√≥ria
            self.executar_analise_exploratoria()

            # 4. Treinar modelos ML
            self.treinar_modelos_ml()

            # 5. Criar visualiza√ß√µes
            self.criar_visualizacoes_completas()

            # 6. Criar mapa interativo do Brasil
            self.criar_mapa_brasil_interativo()

            # 7. An√°lise de insights
            self.gerar_insights_inteligentes()

            # 8. Testar predi√ß√µes
            self.testar_predicoes_cenarios()

            # 9. Exportar resultados
            self.exportar_resultados_completos()

            # 10. Resumo final
            self.mostrar_resumo_final()

            return self.df

        except Exception as e:
            print(f"‚ùå Erro na execu√ß√£o: {str(e)}")
            return None

    def carregar_dados_reais(self, dataset_path: str) -> pd.DataFrame:
        """Carrega dataset real"""
        print(f"üìä Carregando dataset: {dataset_path}")
        
        df = pd.read_csv(dataset_path)
        print(f"‚úÖ Dataset carregado: {df.shape}")
        
        # Converter data
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        elif 'measure_date' in df.columns:
            df['Date'] = pd.to_datetime(df['measure_date'], errors='coerce')
        
        return df

    def criar_dados_sinteticos_completos(self) -> pd.DataFrame:
        """Cria dados sint√©ticos completos baseados nos dois sistemas"""
        print("üîÑ Criando dados sint√©ticos avan√ßados...")

        np.random.seed(42)
        
        # Esta√ß√µes meteorol√≥gicas brasileiras (do primeiro c√≥digo)
        stations = [
            # Rio de Janeiro
            ("ALTO DA BOA VISTA", 83007, -22.965833, -43.279167, 347.1, "RJ"),
            ("COPACABANA", 83008, -22.970722, -43.182365, 5.2, "RJ"),
            ("TIJUCA", 83009, -22.925278, -43.238889, 80.0, "RJ"),
            ("BARRA DA TIJUCA", 83010, -23.018056, -43.365833, 2.1, "RJ"),

            # S√£o Paulo
            ("MIRANTE DE SANTANA", 83004, -23.503056, -46.618333, 792.1, "SP"),
            ("CONGONHAS", 83005, -23.627778, -46.656111, 803.7, "SP"),
            ("IBIRAPUERA", 83006, -23.587500, -46.660833, 733.4, "SP"),

            # Outras regi√µes
            ("BELO HORIZONTE", 83587, -19.932222, -43.937778, 915.0, "MG"),
            ("BRASILIA DF", 83377, -15.789444, -47.925833, 1159.5, "DF"),
            ("SALVADOR", 83229, -12.910833, -38.331667, 51.4, "BA"),
            ("FORTALEZA", 82397, -3.776389, -38.532222, 26.5, "CE"),
            ("MANAUS", 82331, -3.102778, -60.016667, 67.0, "AM"),
            ("PORTO ALEGRE", 83967, -30.053056, -51.178611, 46.97, "RS"),
            ("CURITIBA", 83842, -25.448056, -49.231944, 923.5, "PR"),
            ("RECIFE", 82599, -8.061111, -34.871111, 10.0, "PE"),
            ("BEL√âM", 82191, -1.379167, -48.477778, 16.0, "PA"),
            ("GOI√ÇNIA", 83423, -16.632222, -49.220833, 741.0, "GO"),
            ("CAMPO GRANDE", 83612, -20.469444, -54.613889, 532.0, "MS"),
            ("FLORIAN√ìPOLIS", 83897, -27.583333, -48.566667, 1.8, "SC"),
            ("VIT√ìRIA", 83648, -20.315278, -40.316667, 36.0, "ES")
        ]

        # Gerar dados para 2 anos
        dates = pd.date_range('2022-01-01', '2023-12-31', freq='D')
        sample_data = []

        for date in dates:
            for station_name, station_id, lat, lng, alt, state in stations:
                # Simular temperaturas baseadas na regi√£o e esta√ß√£o
                month = date.month
                
                # Ajustar temperatura base pela latitude (clima brasileiro)
                if lat > -10:  # Norte/Nordeste
                    base_summer, base_winter = 35, 28
                    var_summer, var_winter = 3, 2
                elif lat > -20:  # Centro-Oeste
                    base_summer, base_winter = 32, 25
                    var_summer, var_winter = 4, 3
                elif lat > -25:  # Sudeste
                    base_summer, base_winter = 30, 22
                    var_summer, var_winter = 4, 4
                else:  # Sul
                    base_summer, base_winter = 28, 18
                    var_summer, var_winter = 3, 5

                # Ajustar pela altitude
                altitude_adj = -alt * 0.006

                # Calcular temperaturas sazonais
                if month in [12, 1, 2]:  # Ver√£o
                    max_temp = np.random.normal(base_summer + altitude_adj, var_summer)
                    min_temp = np.random.normal(base_summer - 8 + altitude_adj, var_summer-1)
                elif month in [6, 7, 8]:  # Inverno
                    max_temp = np.random.normal(base_winter + altitude_adj, var_winter)
                    min_temp = np.random.normal(base_winter - 7 + altitude_adj, var_winter-1)
                else:  # Outono/Primavera
                    avg_temp = (base_summer + base_winter) / 2
                    max_temp = np.random.normal(avg_temp + altitude_adj, (var_summer + var_winter)/2)
                    min_temp = np.random.normal(avg_temp - 8 + altitude_adj, (var_summer + var_winter)/2)

                # Popula√ß√£o estimada por regi√£o
                pop_base = {
                    'SP': 2000000, 'RJ': 1500000, 'MG': 800000, 'RS': 600000,
                    'PR': 500000, 'BA': 700000, 'PE': 600000, 'CE': 500000,
                    'AM': 400000, 'PA': 300000, 'DF': 800000, 'GO': 400000,
                    'MS': 300000, 'SC': 400000, 'ES': 350000
                }.get(state, 300000)
                
                population = int(pop_base * np.random.uniform(0.3, 1.5))

                # Simular eventos de desastre (probabil√≠stico)
                disaster_prob = 0.05  # 5% de chance de evento
                if np.random.random() < disaster_prob:
                    # Criar evento de desastre
                    disaster_types = ['Inundacao', 'Seca', 'Vendaval', 'Incendio', 'Deslizamento']
                    disaster_type = np.random.choice(disaster_types)
                    
                    # Severidade baseada no tipo e condi√ß√µes
                    if disaster_type == 'Inundacao' and month in [11, 12, 1, 2, 3]:
                        severity = np.random.exponential(2)
                    elif disaster_type == 'Seca' and month in [6, 7, 8, 9]:
                        severity = np.random.exponential(1.5)
                    elif disaster_type == 'Incendio' and max_temp > 35:
                        severity = np.random.exponential(1.8)
                    else:
                        severity = np.random.exponential(1)
                    
                    # Calcular impactos humanos
                    dead = max(0, int(np.random.poisson(severity * 2)))
                    injured = max(0, int(np.random.poisson(severity * 10)))
                    ill = max(0, int(np.random.poisson(severity * 8)))
                    homeless = max(0, int(np.random.poisson(severity * 50)))
                    displaced = max(0, int(np.random.poisson(severity * 100)))
                    other_affected = max(0, int(np.random.poisson(severity * 20)))
                    
                    complaint_code = f"{np.random.randint(11, 32)}{np.random.randint(1000, 9999)}"
                else:
                    # Dia normal sem eventos
                    dead = injured = ill = homeless = displaced = other_affected = 0
                    disaster_type = 'Normal'
                    complaint_code = None

                # Adicionar ru√≠do realista
                if np.random.random() < 0.02:  # 2% de dados faltantes
                    max_temp = np.nan
                if np.random.random() < 0.02:
                    min_temp = np.nan

                record = {
                    'Date': date,
                    'station_name': station_name,
                    'station_id': station_id,
                    'State': state,
                    'City': f"{station_name.split()[0]}-{state}",
                    'latitude': lat,
                    'longitude': lng,
                    'altitude': alt,
                    'max_temperature': round(max_temp, 1) if not pd.isna(max_temp) else np.nan,
                    'min_temperature': round(min_temp, 1) if not pd.isna(min_temp) else np.nan,
                    'Population': population,
                    'Dead': dead,
                    'Enjuried': injured,
                    'Ill': ill,
                    'Homeless': homeless,
                    'Displaced': displaced,
                    'Other_affected': other_affected,
                    'Disaster_Type': disaster_type,
                    'Complaint': complaint_code
                }

                sample_data.append(record)

        df = pd.DataFrame(sample_data)
        print(f"‚úÖ Dados sint√©ticos criados: {len(df):,} registros de {len(stations)} esta√ß√µes")
        return df

    def preparar_dados_completos(self) -> pd.DataFrame:
        """Prepara e limpa os dados de forma abrangente"""
        print("\nüîß PREPARANDO E CRIANDO FEATURES AVAN√áADAS")
        print("="*50)

        df = self.df.copy()

        # Limpeza b√°sica
        df = self.limpar_dados_basicos(df)

        # Features temporais
        df['year'] = df['Date'].dt.year
        df['month'] = df['Date'].dt.month
        df['quarter'] = df['Date'].dt.quarter
        df['day_of_year'] = df['Date'].dt.dayofyear
        df['season'] = df['month'].apply(self._get_season)
        df['is_rainy_season'] = ((df['month'] >= 11) | (df['month'] <= 3)).astype(int)
        df['is_dry_season'] = ((df['month'] >= 5) & (df['month'] <= 9)).astype(int)

        # Features clim√°ticas
        if 'max_temperature' in df.columns and 'min_temperature' in df.columns:
            df['temp_amplitude'] = df['max_temperature'] - df['min_temperature']
            df['temp_average'] = (df['max_temperature'] + df['min_temperature']) / 2
            df['heat_stress'] = np.where(df['max_temperature'] > 35, 
                                       (df['max_temperature'] - 35) * 2, 0)
            df['cold_stress'] = np.where(df['min_temperature'] < 10, 
                                       (10 - df['min_temperature']) * 3, 0)
            df['extreme_heat'] = (df['max_temperature'] > 40).astype(int)
            df['extreme_cold'] = (df['min_temperature'] < 5).astype(int)

        # Categorizar regi√µes
        df['region'] = df['latitude'].apply(self._categorize_region)

        # Features de impacto humano
        human_cols = ['Dead', 'Enjuried', 'Ill', 'Homeless', 'Displaced', 'Other_affected']
        existing_human_cols = [col for col in human_cols if col in df.columns]
        
        if existing_human_cols:
            df['total_human_impact'] = df[existing_human_cols].fillna(0).sum(axis=1)
            df['critical_impact'] = df[['Dead', 'Enjuried', 'Ill']].fillna(0).sum(axis=1)
            df['displacement_impact'] = df[['Homeless', 'Displaced']].fillna(0).sum(axis=1)
        else:
            df['total_human_impact'] = 0
            df['critical_impact'] = 0
            df['displacement_impact'] = 0

        # √çndice de necessidade (do primeiro c√≥digo)
        df['need_index'] = np.clip(df['heat_stress'] + df['cold_stress'] + 
                                 df['total_human_impact']/10, 0, 100)

        # Features populacionais
        if 'Population' in df.columns:
            df['urban_indicator'] = (df['Population'] > 100000).astype(int)
            df['metropolitan_indicator'] = (df['Population'] > 1000000).astype(int)
            df['impact_rate_per_capita'] = (df['total_human_impact'] / 
                                           df['Population'].replace(0, 1) * 1000)

        # Categorizar desastres
        if 'Disaster_Type' in df.columns:
            df['disaster_category'] = df['Disaster_Type']
        elif 'Complaint' in df.columns:
            df['disaster_category'] = df['Complaint'].apply(self._categorize_disaster)
        else:
            df['disaster_category'] = 'Normal'

        # TARGET: Categoria de necessidade priorit√°ria
        df['priority_need_category'] = df.apply(self._determine_priority_need, axis=1)

        # Score de severidade
        df['severity_score'] = (df['critical_impact'] * 10 + 
                              df['displacement_impact'] * 5 + 
                              df['total_human_impact'] * 2)

        # N√≠vel de urg√™ncia
        df['urgency_level'] = pd.cut(df['need_index'], 
                                   bins=[0, 20, 40, 70, 100],
                                   labels=['Baixa', 'Moderada', 'Alta', 'Cr√≠tica'],
                                   include_lowest=True)

        print(f"‚úÖ Features criadas! Dataset final: {df.shape}")
        return df

    def limpar_dados_basicos(self, df: pd.DataFrame) -> pd.DataFrame:
        """Limpeza b√°sica dos dados"""
        
        # Preencher valores ausentes de temperatura por regi√£o
        if 'latitude' in df.columns:
            df['region_temp'] = df['latitude'].apply(self._categorize_region)
            
            for region in df['region_temp'].unique():
                mask = df['region_temp'] == region
                if 'max_temperature' in df.columns:
                    df.loc[mask, 'max_temperature'] = df.loc[mask, 'max_temperature'].fillna(
                        df.loc[mask, 'max_temperature'].median())
                if 'min_temperature' in df.columns:
                    df.loc[mask, 'min_temperature'] = df.loc[mask, 'min_temperature'].fillna(
                        df.loc[mask, 'min_temperature'].median())

        # Preencher dados populacionais
        if 'Population' in df.columns:
            df['Population'] = df['Population'].fillna(300000)

        # Preencher impactos humanos com 0
        human_cols = ['Dead', 'Enjuried', 'Ill', 'Homeless', 'Displaced', 'Other_affected']
        for col in human_cols:
            if col in df.columns:
                df[col] = df[col].fillna(0)

        return df

    def _get_season(self, month):
        """Determina a esta√ß√£o do ano (hemisf√©rio sul)"""
        seasons = {
            12: 'Ver√£o', 1: 'Ver√£o', 2: 'Ver√£o',
            3: 'Outono', 4: 'Outono', 5: 'Outono',
            6: 'Inverno', 7: 'Inverno', 8: 'Inverno',
            9: 'Primavera', 10: 'Primavera', 11: 'Primavera'
        }
        return seasons[month]

    def _categorize_region(self, lat):
        """Categoriza a regi√£o baseada na latitude"""
        if pd.isna(lat):
            return 'Sudeste'
        elif lat > -5:
            return 'Norte'
        elif lat > -15:
            return 'Nordeste'
        elif lat > -20:
            return 'Centro-Oeste'
        elif lat > -25:
            return 'Sudeste'
        else:
            return 'Sul'

    def _categorize_disaster(self, complaint):
        """Categoriza tipo de desastre"""
        if pd.isna(complaint):
            return 'Normal'
        
        code_str = str(complaint)[:2]
        disaster_map = {
            '11': 'Seca', '12': 'Incendio', '13': 'Inundacao',
            '14': 'Vendaval', '15': 'Granizo', '16': 'Tornado',
            '21': 'Terremoto', '22': 'Deslizamento',
            '31': 'Contaminacao', '32': 'Epidemia'
        }
        return disaster_map.get(code_str, 'Outros')

    def _determine_priority_need(self, row):
        """Determina necessidade priorit√°ria"""
        mortality = row.get('Dead', 0)
        injured = row.get('Enjuried', 0) + row.get('Ill', 0)
        homeless = row.get('Homeless', 0)
        temp_max = row.get('max_temperature', 25)
        temp_min = row.get('min_temperature', 15)
        disaster_cat = row.get('disaster_category', 'Normal')

        if mortality > 5 or injured > 50:
            return 'Emergencia_Medica'
        elif homeless > 100:
            return 'Abrigo_Emergencial'
        elif disaster_cat in ['Inundacao', 'Deslizamento']:
            return 'Saneamento_Limpeza'
        elif disaster_cat in ['Seca', 'Incendio'] or temp_max > 40:
            return 'Agua_Alimentacao'
        elif temp_min < 5:
            return 'Agasalhos_Aquecimento'
        elif injured > 10:
            return 'Medicamentos_Saude'
        else:
            return 'Apoio_Geral'

    def executar_analise_exploratoria(self):
        """Executa an√°lise explorat√≥ria completa"""
        print("\nüìä AN√ÅLISE EXPLORAT√ìRIA DE DADOS")
        print("="*50)

        # Estat√≠sticas gerais
        self.mostrar_overview_statistics()

        # An√°lise regional
        self.analisar_regioes()

        # Padr√µes sazonais
        self.analisar_padroes_sazonais()

        # Eventos extremos
        self.analisar_eventos_extremos()

        # An√°lise de necessidades
        self.analisar_necessidades()

    def mostrar_overview_statistics(self):
        """Mostra estat√≠sticas gerais"""
        print(f"\nüìÖ Per√≠odo: {self.df['Date'].min().date()} at√© {self.df['Date'].max().date()}")
        print(f"üó∫Ô∏è  Esta√ß√µes: {self.df['station_name'].nunique() if 'station_name' in self.df.columns else 'N/A'}")
        print(f"üèõÔ∏è  Estados: {self.df['State'].nunique()}")
        print(f"üìç Regi√µes: {self.df['region'].nunique()}")
        print(f"üìä Total de registros: {len(self.df):,}")

        if 'max_temperature' in self.df.columns:
            temp_stats = self.df[['max_temperature', 'min_temperature', 'temp_average']].describe()
            print(f"\nüå°Ô∏è  ESTAT√çSTICAS DE TEMPERATURA")
            print(temp_stats.round(2))

        print(f"\nüë• IMPACTO HUMANO TOTAL:")
        print(f"   Pessoas afetadas: {self.df['total_human_impact'].sum():,}")
        print(f"   Eventos com impacto: {(self.df['total_human_impact'] > 0).sum():,}")

    def analisar_regioes(self):
        """An√°lise por regi√£o"""
        print(f"\nüó∫Ô∏è  AN√ÅLISE REGIONAL")
        print("-" * 30)

        regional_stats = self.df.groupby('region').agg({
            'temp_average': 'mean',
            'need_index': 'mean',
            'total_human_impact': 'sum',
            'State': 'nunique'
        }).round(2)

        for region in regional_stats.index:
            stats = regional_stats.loc[region]
            print(f"\nüî∏ {region}:")
            print(f"   Estados: {int(stats['State'])}")
            print(f"   Temp. m√©dia: {stats['temp_average']:.1f}¬∞C")
            print(f"   √çndice necessidade: {stats['need_index']:.1f}/100")
            print(f"   Pessoas afetadas: {int(stats['total_human_impact']):,}")

    def analisar_padroes_sazonais(self):
        """An√°lise de padr√µes sazonais"""
        print(f"\nüåÄ PADR√ïES SAZONAIS")
        print("-" * 30)

        seasonal_stats = self.df.groupby(['region', 'season']).agg({
            'temp_average': 'mean',
            'need_index': 'mean'
        }).round(2)

        print("üå°Ô∏è  Temperatura m√©dia por esta√ß√£o e regi√£o:")
        temp_pivot = seasonal_stats['temp_average'].unstack(fill_value=0)
        print(temp_pivot)

    def analisar_eventos_extremos(self):
        """An√°lise de eventos extremos"""
        print(f"\nüö® EVENTOS EXTREMOS")
        print("-" * 30)

        hot_days = self.df[self.df['max_temperature'] > 35] if 'max_temperature' in self.df.columns else pd.DataFrame()
        cold_days = self.df[self.df['min_temperature'] < 10] if 'min_temperature' in self.df.columns else pd.DataFrame()
        impact_events = self.df[self.df['total_human_impact'] > 100]

        print(f"üî• Dias muito quentes (>35¬∞C): {len(hot_days):,}")
        print(f"‚ùÑÔ∏è  Dias muito frios (<10¬∞C): {len(cold_days):,}")
        print(f"üë• Eventos de alto impacto (>100 pessoas): {len(impact_events):,}")

    def analisar_necessidades(self):
        """An√°lise do √≠ndice de necessidade"""
        print(f"\nüéØ AN√ÅLISE DE NECESSIDADES")
        print("-" * 30)

        urgency_counts = self.df['urgency_level'].value_counts()
        print(f"üö® Distribui√ß√£o por Urg√™ncia:")
        for level, count in urgency_counts.items():
            print(f"   {level}: {count:,} ({count/len(self.df)*100:.1f}%)")

        if 'priority_need_category' in self.df.columns:
            need_counts = self.df['priority_need_category'].value_counts().head(5)
            print(f"\nüéØ Top 5 Necessidades:")
            for need, count in need_counts.items():
                print(f"   {need}: {count:,}")

    def treinar_modelos_ml(self):
        """Treina modelos de Machine Learning"""
        print("\nü§ñ TREINANDO MODELOS DE MACHINE LEARNING")
        print("="*50)

        # Preparar features para ML
        feature_cols = self.selecionar_features_ml()
        X = self.df[feature_cols].copy()

        # Encoding de vari√°veis categ√≥ricas
        categorical_features = ['State', 'disaster_category', 'season', 'region']
        for col in categorical_features:
            if col in X.columns:
                if col not in self.encoders:
                    self.encoders[col] = LabelEncoder()
                X[f'{col}_encoded'] = self.encoders[col].fit_transform(X[col].astype(str))
                X = X.drop(columns=[col])

        # Preencher NaN e guardar nomes das features
        X = X.fillna(0)
        self.feature_names = X.columns.tolist()

        print(f"üìä Features para ML: {len(self.feature_names)}")

        # Treinar modelos
        self.treinar_modelo_necessidades(X)
        self.treinar_modelo_impacto(X)

        print("‚úÖ Modelos treinados com sucesso!")

    def selecionar_features_ml(self):
        """Seleciona features para ML"""
        base_features = [
            'year', 'month', 'quarter', 'is_rainy_season', 'is_dry_season',
            'latitude', 'longitude', 'altitude', 'Population'
        ]

        if 'max_temperature' in self.df.columns:
            base_features.extend([
                'max_temperature', 'min_temperature', 'temp_average',
                'temp_amplitude', 'heat_stress', 'cold_stress'
            ])

        categorical_features = ['State', 'disaster_category', 'season', 'region']

        # Filtrar features existentes
        available_features = [f for f in base_features if f in self.df.columns]
        available_categorical = [f for f in categorical_features if f in self.df.columns]

        return available_features + available_categorical

    def treinar_modelo_necessidades(self, X):
        """Treina modelo de predi√ß√£o de necessidades"""
        print("\nüéØ Treinando modelo de necessidades...")

        y = self.df['priority_need_category'].fillna('Apoio_Geral')

        # Encoding do target
        if 'need_category' not in self.encoders:
            self.encoders['need_category'] = LabelEncoder()
        y_encoded = self.encoders['need_category'].fit_transform(y)

        # Split e scaling
        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

        if 'need_scaler' not in self.scalers:
            self.scalers['need_scaler'] = StandardScaler()
        X_train_scaled = self.scalers['need_scaler'].fit_transform(X_train)
        X_test_scaled = self.scalers['need_scaler'].transform(X_test)

        # RandomForest
        rf = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42, class_weight='balanced')
        rf.fit(X_train_scaled, y_train)
        self.ml_models['need_predictor'] = rf

        # Avaliar
        y_pred = rf.predict(X_test_scaled)
        accuracy = (y_pred == y_test).mean()
        print(f"‚úÖ Acur√°cia do modelo: {accuracy:.3f}")

    def treinar_modelo_impacto(self, X):
        """Treina modelo de predi√ß√£o de impacto"""
        print("\nüë• Treinando modelo de impacto...")

        y_impact = self.df['total_human_impact'].fillna(0)

        # Transforma√ß√£o log para valores positivos
        y_impact_log = np.log1p(y_impact)

        # Split e scaling
        X_train, X_test, y_train, y_test = train_test_split(X, y_impact_log, test_size=0.2, random_state=42)

        if 'impact_scaler' not in self.scalers:
            self.scalers['impact_scaler'] = RobustScaler()
        X_train_scaled = self.scalers['impact_scaler'].fit_transform(X_train)
        X_test_scaled = self.scalers['impact_scaler'].transform(X_test)

        # GradientBoosting
        gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42)
        gb.fit(X_train_scaled, y_train)
        self.ml_models['impact_predictor'] = gb

        # Avaliar
        y_pred_log = gb.predict(X_test_scaled)
        y_pred = np.expm1(y_pred_log)
        y_test_original = np.expm1(y_test)

        rmse = np.sqrt(mean_squared_error(y_test_original, y_pred))
        r2 = r2_score(y_test_original, y_pred)
        print(f"‚úÖ RMSE: {rmse:.2f} pessoas")
        print(f"‚úÖ R¬≤ Score: {r2:.3f}")

    def criar_visualizacoes_completas(self):
        """Cria dashboard completo com visualiza√ß√µes"""
        print("\nüìä CRIANDO DASHBOARD COMPLETO")
        print("="*50)

        fig, axes = plt.subplots(4, 3, figsize=(20, 24))
        fig.suptitle('üåü SOLIDARIA - DASHBOARD COMPLETO UNIFICADO', fontsize=16, fontweight='bold')

        # 1. Estados mais afetados
        if 'State' in self.df.columns:
            state_impact = self.df.groupby('State')['total_human_impact'].sum().sort_values(ascending=False).head(10)
            axes[0,0].barh(range(len(state_impact)), state_impact.values, color='red', alpha=0.7)
            axes[0,0].set_yticks(range(len(state_impact)))
            axes[0,0].set_yticklabels(state_impact.index)
            axes[0,0].set_title('üèõÔ∏è Top 10 Estados Mais Afetados')
            axes[0,0].set_xlabel('Pessoas Afetadas')

        # 2. Distribui√ß√£o de temperaturas por regi√£o
        if 'max_temperature' in self.df.columns:
            self.df.boxplot(column='temp_average', by='region', ax=axes[0,1])
            axes[0,1].set_title('üå°Ô∏è Temperatura M√©dia por Regi√£o')
            axes[0,1].set_xlabel('Regi√£o')
            axes[0,1].set_ylabel('Temperatura (¬∞C)')

        # 3. Evolu√ß√£o temporal dos eventos
        monthly_data = self.df.groupby(self.df['Date'].dt.to_period('M'))['total_human_impact'].sum()
        axes[0,2].plot(range(len(monthly_data)), monthly_data.values, marker='o', color='blue')
        axes[0,2].set_title('üìà Evolu√ß√£o Temporal dos Impactos')
        axes[0,2].set_xlabel('Per√≠odo (Meses)')
        axes[0,2].set_ylabel('Pessoas Afetadas')

        # 4. Distribui√ß√£o de necessidades
        need_counts = self.df['priority_need_category'].value_counts()
        colors = plt.cm.Set3(np.linspace(0, 1, len(need_counts)))
        axes[1,0].pie(need_counts.values, labels=need_counts.index, autopct='%1.1f%%', colors=colors)
        axes[1,0].set_title('üéØ Distribui√ß√£o de Necessidades')

        # 5. Padr√µes sazonais
        seasonal_temps = self.df.groupby(['season', 'region'])['temp_average'].mean().unstack(fill_value=0)
        seasonal_temps.plot(kind='bar', ax=axes[1,1], colormap='viridis')
        axes[1,1].set_title('üåÄ Temperatura por Esta√ß√£o e Regi√£o')
        axes[1,1].set_xlabel('Esta√ß√£o')
        axes[1,1].tick_params(axis='x', rotation=45)
        axes[1,1].legend(title='Regi√£o', bbox_to_anchor=(1.05, 1), loc='upper left')

        # 6. √çndice de necessidade
        self.df['need_index'].hist(bins=30, ax=axes[1,2], color='orange', alpha=0.7, edgecolor='black')
        axes[1,2].set_title('üìä Distribui√ß√£o do √çndice de Necessidade')
        axes[1,2].set_xlabel('√çndice de Necessidade')
        axes[1,2].set_ylabel('Frequ√™ncia')

        # 7. Correla√ß√£o entre vari√°veis
        corr_vars = ['max_temperature', 'min_temperature', 'temp_amplitude', 'total_human_impact', 'need_index']
        existing_vars = [var for var in corr_vars if var in self.df.columns]
        if len(existing_vars) >= 3:
            corr_matrix = self.df[existing_vars].corr()
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[2,0])
            axes[2,0].set_title('üîó Matriz de Correla√ß√£o')

        # 8. Eventos extremos por m√™s
        monthly_extremes = self.df.groupby('month').agg({
            'heat_stress': lambda x: (x > 0).sum(),
            'cold_stress': lambda x: (x > 0).sum()
        })
        monthly_extremes.plot(kind='bar', ax=axes[2,1], color=['red', 'blue'])
        axes[2,1].set_title('üå°Ô∏è Eventos Extremos por M√™s')
        axes[2,1].set_xlabel('M√™s')
        axes[2,1].set_ylabel('N√∫mero de Eventos')
        axes[2,1].legend(['Estresse Calor', 'Estresse Frio'])

        # 9. Urg√™ncia por regi√£o
        urgency_by_region = pd.crosstab(self.df['region'], self.df['urgency_level'])
        urgency_by_region.plot(kind='bar', stacked=True, ax=axes[2,2], colormap='Reds')
        axes[2,2].set_title('üö® N√≠veis de Urg√™ncia por Regi√£o')
        axes[2,2].set_xlabel('Regi√£o')
        axes[2,2].tick_params(axis='x', rotation=45)

        # 10. Distribui√ß√£o geogr√°fica b√°sica
        if 'latitude' in self.df.columns and 'longitude' in self.df.columns:
            scatter = axes[3,0].scatter(self.df['longitude'], self.df['latitude'], 
                                       c=self.df['total_human_impact'], 
                                       cmap='Reds', alpha=0.6, s=30)
            axes[3,0].set_xlabel('Longitude')
            axes[3,0].set_ylabel('Latitude')
            axes[3,0].set_title('üó∫Ô∏è Distribui√ß√£o Geogr√°fica dos Impactos')
            plt.colorbar(scatter, ax=axes[3,0])

        # 11. Tipos de desastre
        if 'disaster_category' in self.df.columns:
            disaster_counts = self.df[self.df['disaster_category'] != 'Normal']['disaster_category'].value_counts()
            if len(disaster_counts) > 0:
                axes[3,1].bar(disaster_counts.index, disaster_counts.values, color='purple', alpha=0.7)
                axes[3,1].set_title('‚ö° Tipos de Desastres')
                axes[3,1].set_ylabel('Frequ√™ncia')
                axes[3,1].tick_params(axis='x', rotation=45)

        # 12. Amplitude t√©rmica vs Impacto
        if 'temp_amplitude' in self.df.columns:
            axes[3,2].scatter(self.df['temp_amplitude'], self.df['total_human_impact'], alpha=0.6, color='green')
            axes[3,2].set_xlabel('Amplitude T√©rmica (¬∞C)')
            axes[3,2].set_ylabel('Pessoas Afetadas')
            axes[3,2].set_title('üå°Ô∏è Amplitude T√©rmica vs Impacto')

        plt.tight_layout()
        plt.show()
        print("‚úÖ Dashboard criado com 12 visualiza√ß√µes!")

    def criar_mapa_brasil_interativo(self):
        """Cria mapa interativo do Brasil - MANTIDO CONFORME SOLICITADO"""
        print("\nüó∫Ô∏è CRIANDO MAPA INTERATIVO DO BRASIL")
        print("="*50)

        try:
            # Agregar dados por esta√ß√£o/localiza√ß√£o
            if 'station_name' in self.df.columns:
                location_summary = self.df.groupby(['station_name', 'latitude', 'longitude', 'region', 'State']).agg({
                    'temp_average': 'mean',
                    'need_index': 'mean',
                    'total_human_impact': 'sum',
                    'max_temperature': 'max',
                    'min_temperature': 'min',
                    'urgency_level': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Baixa'
                }).reset_index().round(2)
            else:
                location_summary = self.df.groupby(['State', 'latitude', 'longitude', 'region']).agg({
                    'temp_average': 'mean',
                    'need_index': 'mean',
                    'total_human_impact': 'sum',
                    'max_temperature': 'max',
                    'min_temperature': 'min',
                    'urgency_level': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Baixa'
                }).reset_index().round(2)
                location_summary['station_name'] = location_summary['State'] + '_Aggregate'

            # Criar mapa interativo
            fig = px.scatter_mapbox(
                location_summary,
                lat='latitude',
                lon='longitude',
                color='need_index',
                size='total_human_impact',
                hover_name='station_name',
                hover_data={
                    'State': True,
                    'region': True,
                    'temp_average': ':.1f',
                    'need_index': ':.1f',
                    'total_human_impact': ':,',
                    'max_temperature': ':.1f',
                    'min_temperature': ':.1f',
                    'urgency_level': True
                },
                color_continuous_scale='RdYlBu_r',
                title='üáßüá∑ MAPA DO BRASIL - SolidarIA<br>√çndice de Necessidade e Impactos Humanit√°rios',
                mapbox_style='open-street-map',
                zoom=3.5,
                center={'lat': -15, 'lon': -50},
                width=1000,
                height=700
            )

            # Personalizar layout do mapa
            fig.update_layout(
                mapbox_style="open-street-map",
                margin={"r":0,"t":50,"l":0,"b":0},
                font=dict(size=12),
                title_font_size=16,
                coloraxis_colorbar=dict(
                    title="√çndice de Necessidade",
                    titleside="top"
                )
            )

            # Adicionar anota√ß√µes para contextualizar
            fig.add_annotation(
                text="üî¥ Maior necessidade | üîµ Menor necessidade<br>‚ö´ Tamanho = Total de pessoas afetadas",
                showarrow=False,
                x=0.02, y=0.98,
                xref="paper", yref="paper",
                xanchor="left", yanchor="top",
                bgcolor="rgba(255,255,255,0.8)",
                bordercolor="black",
                borderwidth=1
            )

            fig.show()

            # Estat√≠sticas do mapa
            print(f"üìç Localiza√ß√µes mapeadas: {len(location_summary)}")
            print(f"üèõÔ∏è Estados representados: {location_summary['State'].nunique()}")
            print(f"üå°Ô∏è Necessidade m√©dia nacional: {location_summary['need_index'].mean():.1f}")
            print(f"üë• Total de pessoas afetadas: {location_summary['total_human_impact'].sum():,}")

            # Top 5 locais com maior necessidade
            top_needs = location_summary.nlargest(5, 'need_index')
            print(f"\nüéØ TOP 5 LOCAIS COM MAIOR NECESSIDADE:")
            for _, row in top_needs.iterrows():
                print(f"   {row['station_name']} ({row['State']}): {row['need_index']:.1f}")

            print("‚úÖ Mapa interativo do Brasil criado com sucesso!")

        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao criar mapa: {str(e)}")
            print("üìä Criando visualiza√ß√£o alternativa...")
            
            # Mapa alternativo simples
            plt.figure(figsize=(12, 8))
            scatter = plt.scatter(self.df['longitude'], self.df['latitude'], 
                                c=self.df['need_index'], cmap='RdYlBu_r', 
                                s=self.df['total_human_impact']/10 + 20, alpha=0.7)
            plt.colorbar(scatter, label='√çndice de Necessidade')
            plt.xlabel('Longitude')
            plt.ylabel('Latitude')
            plt.title('üáßüá∑ Mapa do Brasil - √çndice de Necessidade SolidarIA')
            plt.grid(True, alpha=0.3)
            plt.show()

    def gerar_insights_inteligentes(self):
        """Gera insights e recomenda√ß√µes inteligentes"""
        print("\nüí° SOLIDARIA INSIGHTS - ESTRAT√âGIAS INTELIGENTES")
        print("ü§ñ Recomenda√ß√µes Baseadas em Intelig√™ncia Artificial")
        print("="*70)

        insights = []

        # Insight 1: Regi√µes mais necessitadas
        region_needs = self.df.groupby('region')['need_index'].mean().sort_values(ascending=False)
        top_region = region_needs.index[0]
        insights.append(f"üéØ Regi√£o priorit√°ria: {top_region} (√≠ndice m√©dio: {region_needs.iloc[0]:.1f})")

        # Insight 2: Sazonalidade
        season_needs = self.df.groupby('season')['need_index'].mean().sort_values(ascending=False)
        peak_season = season_needs.index[0]
        insights.append(f"üìÖ Pico de necessidade: {peak_season} (√≠ndice: {season_needs.iloc[0]:.1f})")

        # Insight 3: Estados mais cr√≠ticos
        state_impact = self.df.groupby('State')['total_human_impact'].sum().sort_values(ascending=False)
        critical_state = state_impact.index[0]
        insights.append(f"üö® Estado mais cr√≠tico: {critical_state} ({state_impact.iloc[0]:,} pessoas afetadas)")

        # Insight 4: Eventos extremos
        extreme_pct = ((self.df['need_index'] > 50).sum() / len(self.df)) * 100
        insights.append(f"‚ö° {extreme_pct:.1f}% dos registros apresentam necessidade alta/cr√≠tica")

        # Insight 5: Correla√ß√£o temperatura-necessidade
        if 'temp_average' in self.df.columns:
            temp_corr = self.df['temp_average'].corr(self.df['need_index'])
            direction = "positiva" if temp_corr > 0 else "negativa"
            insights.append(f"üå°Ô∏è Correla√ß√£o {direction} entre temperatura e necessidade (r={temp_corr:.2f})")

        # Insight 6: Necessidade mais comum
        most_common_need = self.df['priority_need_category'].value_counts().index[0]
        insights.append(f"üéØ Necessidade mais frequente: {most_common_need}")

        # Mostrar insights
        for i, insight in enumerate(insights, 1):
            print(f"{i}. {insight}")

        # Recomenda√ß√µes estrat√©gicas
        print(f"\nüéØ RECOMENDA√á√ïES ESTRAT√âGICAS:")
        print(f"   ‚Ä¢ Priorizar campanhas na regi√£o {top_region}")
        print(f"   ‚Ä¢ Intensificar a√ß√µes durante o {peak_season}")
        print(f"   ‚Ä¢ Focar recursos no estado {critical_state}")
        print(f"   ‚Ä¢ Manter estoque de emerg√™ncia para {extreme_pct:.0f}% dos dias cr√≠ticos")
        print(f"   ‚Ä¢ Preparar log√≠stica para {most_common_need}")
        print(f"   ‚Ä¢ Monitorar padr√µes clim√°ticos extremos")

        return insights

    def testar_predicoes_cenarios(self):
        """Testa predi√ß√µes com cen√°rios realistas"""
        print("\nüîÆ TESTANDO PREDI√á√ïES COM CEN√ÅRIOS")
        print("="*50)

        cenarios = [
            {
                'nome': 'üåä Enchente Grande S√£o Paulo',
                'dados': {
                    'State': 'SP', 'max_temperature': 32, 'min_temperature': 22,
                    'Population': 12000000, 'month': 1, 'disaster_category': 'Inundacao',
                    'latitude': -23.5, 'longitude': -46.6
                }
            },
            {
                'nome': 'üî• Seca Severa no Nordeste',
                'dados': {
                    'State': 'CE', 'max_temperature': 42, 'min_temperature': 28,
                    'Population': 800000, 'month': 8, 'disaster_category': 'Seca',
                    'latitude': -3.7, 'longitude': -38.5
                }
            },
            {
                'nome': '‚ùÑÔ∏è Onda de Frio no Sul',
                'dados': {
                    'State': 'RS', 'max_temperature': 8, 'min_temperature': -2,
                    'Population': 500000, 'month': 7, 'disaster_category': 'Normal',
                    'latitude': -30.0, 'longitude': -51.2
                }
            },
            {
                'nome': '‚ö° Tempestade Rio de Janeiro',
                'dados': {
                    'State': 'RJ', 'max_temperature': 35, 'min_temperature': 25,
                    'Population': 6000000, 'month': 3, 'disaster_category': 'Vendaval',
                    'latitude': -22.9, 'longitude': -43.2
                }
            }
        ]

        for cenario in cenarios:
            print(f"\n{cenario['nome']}")
            print("-" * 40)

            resultado = self.fazer_predicao(cenario['dados'])

            if 'error' not in resultado:
                print(f"üí° Necessidade Prevista: {resultado.get('necessidade', 'N/A')}")
                print(f"üéØ Confian√ßa: {resultado.get('confianca', 0):.1%}")
                print(f"üë• Impacto Estimado: {resultado.get('impacto_estimado', 0):,} pessoas")
                print(f"‚ö†Ô∏è Prioridade: {resultado.get('prioridade', 'N/A')}")

                recomendacoes = resultado.get('recomendacoes', [])[:3]
                if recomendacoes:
                    print("üìã Principais Recomenda√ß√µes:")
                    for i, rec in enumerate(recomendacoes, 1):
                        print(f"  {i}. {rec}")
            else:
                print(f"‚ùå Erro: {resultado['error']}")

    def fazer_predicao(self, dados: Dict) -> Dict:
        """Faz predi√ß√£o para um cen√°rio espec√≠fico"""
        try:
            # Resultado padr√£o
            resultado = {
                'necessidade': 'Apoio_Geral',
                'confianca': 0.7,
                'impacto_estimado': 150,
                'prioridade': 'M√âDIA',
                'recomendacoes': []
            }

            # L√≥gica de predi√ß√£o baseada nas regras
            max_temp = dados.get('max_temperature', 25)
            min_temp = dados.get('min_temperature', 15)
            population = dados.get('Population', 100000)
            disaster = dados.get('disaster_category', 'Normal')

            # Determinar necessidade
            if disaster == 'Inundacao':
                resultado['necessidade'] = 'Saneamento_Limpeza'
                resultado['impacto_estimado'] = int(population * 0.05)
                resultado['confianca'] = 0.85
            elif disaster == 'Seca':
                resultado['necessidade'] = 'Agua_Alimentacao'
                resultado['impacto_estimado'] = int(population * 0.03)
                resultado['confianca'] = 0.80
            elif min_temp < 5:
                resultado['necessidade'] = 'Agasalhos_Aquecimento'
                resultado['impacto_estimado'] = int(population * 0.02)
                resultado['confianca'] = 0.75
            elif max_temp > 40:
                resultado['necessidade'] = 'Agua_Alimentacao'
                resultado['impacto_estimado'] = int(population * 0.025)
                resultado['confianca'] = 0.70

            # Calcular prioridade
            score = 0
            if 'Emergencia' in resultado['necessidade']:
                score += 50
            elif 'Agua' in resultado['necessidade']:
                score += 40
            elif 'Abrigo' in resultado['necessidade']:
                score += 35

            if max_temp > 40 or min_temp < 5:
                score += 20
            if population > 1000000:
                score += 15

            if score >= 70:
                resultado['prioridade'] = 'CR√çTICA'
            elif score >= 50:
                resultado['prioridade'] = 'ALTA'
            elif score >= 30:
                resultado['prioridade'] = 'M√âDIA'
            else:
                resultado['prioridade'] = 'BAIXA'

            # Gerar recomenda√ß√µes
            resultado['recomendacoes'] = self.gerar_recomendacoes_cenario(resultado, dados)

            return resultado

        except Exception as e:
            return {'error': f'Erro na predi√ß√£o: {str(e)}'}

    def gerar_recomendacoes_cenario(self, resultado: Dict, dados: Dict) -> List[str]:
        """Gera recomenda√ß√µes espec√≠ficas para o cen√°rio"""
        recomendacoes = []
        necessidade = resultado.get('necessidade', '')

        # Recomenda√ß√µes por necessidade
        if 'Agua_Alimentacao' in necessidade:
            recomendacoes.extend([
                'üíß CR√çTICO: Distribuir √°gua pot√°vel imediatamente',
                'ü•´ Organizar cestas b√°sicas de emerg√™ncia',
                'üöõ Mobilizar caminh√µes-pipa'
            ])
        elif 'Saneamento_Limpeza' in necessidade:
            recomendacoes.extend([
                'üßπ URGENTE: Organizar mutir√£o de limpeza',
                'üè• Providenciar kits de higiene',
                'üíä Distribuir medicamentos preventivos'
            ])
        elif 'Agasalhos_Aquecimento' in necessidade:
            recomendacoes.extend([
                'üß• PRIORIT√ÅRIO: Distribuir cobertores e roupas',
                'üî• Instalar aquecedores em abrigos',
                '‚òï Organizar pontos de bebidas quentes'
            ])
        else:
            recomendacoes.extend([
                'üì¶ Coordenar doa√ß√µes gerais',
                'ü§ù Ativar rede de volunt√°rios',
                'üì¢ Divulgar necessidades espec√≠ficas'
            ])

        # Recomenda√ß√µes por condi√ß√µes
        max_temp = dados.get('max_temperature', 25)
        min_temp = dados.get('min_temperature', 15)
        population = dados.get('Population', 100000)

        if max_temp > 40:
            recomendacoes.append('üå°Ô∏è Instalar pontos de hidrata√ß√£o')
        if min_temp < 0:
            recomendacoes.append('üè† Abrir abrigos de emerg√™ncia')
        if population > 1000000:
            recomendacoes.append('üì¢ Campanha midi√°tica massiva')

        return recomendacoes[:6]

    def exportar_resultados_completos(self):
        """Exporta todos os resultados"""
        print("\nüìÅ EXPORTANDO RESULTADOS COMPLETOS")
        print("="*50)

        results_dir = 'solidaria_results'
        os.makedirs(results_dir, exist_ok=True)

        try:
            # 1. Dataset processado
            self.df.to_csv(f'{results_dir}/dataset_processado_completo.csv', index=False)
            print("‚úÖ Dataset processado exportado")

            # 2. Estat√≠sticas por regi√£o
            regional_stats = self.df.groupby('region').agg({
                'temp_average': ['mean', 'std'],
                'need_index': ['mean', 'max'],
                'total_human_impact': ['sum', 'mean'],
                'State': 'nunique'
            }).round(2)
            regional_stats.to_csv(f'{results_dir}/estatisticas_regionais.csv')
            print("‚úÖ Estat√≠sticas regionais exportadas")

            # 3. Ranking de necessidades
            need_ranking = self.df.groupby('State').agg({
                'need_index': 'mean',
                'total_human_impact': 'sum',
                'priority_need_category': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'N/A'
            }).sort_values('need_index', ascending=False)
            need_ranking.to_csv(f'{results_dir}/ranking_necessidades_estados.csv')
            print("‚úÖ Ranking de necessidades exportado")

            # 4. Relat√≥rio executivo
            self.gerar_relatorio_executivo_completo(f'{results_dir}/relatorio_executivo_completo.txt')
            print("‚úÖ Relat√≥rio executivo exportado")

            # 5. Metadados do sistema
            metadata = {
                'total_registros': len(self.df),
                'periodo_analise': f"{self.df['Date'].min()} a {self.df['Date'].max()}",
                'estados_analisados': self.df['State'].nunique(),
                'total_pessoas_afetadas': int(self.df['total_human_impact'].sum()),
                'modelos_ml': len(self.ml_models),
                'features_criadas': self.df.shape[1],
                'executado_em': datetime.now().isoformat()
            }

            with open(f'{results_dir}/metadata_sistema.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
            print("‚úÖ Metadados exportados")

            print(f"\nüéâ Resultados completos exportados para: {results_dir}/")

        except Exception as e:
            print(f"‚ùå Erro na exporta√ß√£o: {str(e)}")

    def gerar_relatorio_executivo_completo(self, filepath: str):
        """Gera relat√≥rio executivo completo"""
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("RELAT√ìRIO EXECUTIVO COMPLETO - SISTEMA SOLIDARIA UNIFICADO\n")
            f.write("="*80 + "\n\n")

            f.write(f"üìÖ Data de Gera√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
            f.write(f"ü§ñ Sistema: SolidarIA - Marketplace Inteligente de Doa√ß√µes\n")
            f.write(f"üìä Vers√£o: Unificada com ML + EDA + Mapa Brasil\n\n")

            # Resumo executivo
            f.write("üéØ RESUMO EXECUTIVO\n")
            f.write("-" * 50 + "\n")
            f.write(f"‚Ä¢ Registros Analisados: {len(self.df):,}\n")
            f.write(f"‚Ä¢ Per√≠odo: {self.df['Date'].min().strftime('%Y')} - {self.df['Date'].max().strftime('%Y')}\n")
            f.write(f"‚Ä¢ Estados Cobertos: {self.df['State'].nunique()}\n")
            f.write(f"‚Ä¢ Pessoas Afetadas: {self.df['total_human_impact'].sum():,}\n")
            f.write(f"‚Ä¢ √çndice M√©dio Nacional: {self.df['need_index'].mean():.1f}/100\n\n")

            # Top regi√µes cr√≠ticas
            region_needs = self.df.groupby('region')['need_index'].mean().sort_values(ascending=False)
            f.write("üö® REGI√ïES MAIS CR√çTICAS\n")
            f.write("-" * 50 + "\n")
            for i, (region, need) in enumerate(region_needs.head(3).items(), 1):
                f.write(f"{i}. {region}: {need:.1f} pontos\n")

            # Estados priorit√°rios
            state_impact = self.df.groupby('State')['total_human_impact'].sum().sort_values(ascending=False)
            f.write(f"\nüèõÔ∏è ESTADOS PRIORIT√ÅRIOS\n")
            f.write("-" * 50 + "\n")
            for i, (state, impact) in enumerate(state_impact.head(5).items(), 1):
                f.write(f"{i}. {state}: {impact:,} pessoas afetadas\n")

            # Necessidades principais
            need_counts = self.df['priority_need_category'].value_counts()
            f.write(f"\nüéØ NECESSIDADES PRINCIPAIS\n")
            f.write("-" * 50 + "\n")
            for i, (need, count) in enumerate(need_counts.head(3).items(), 1):
                f.write(f"{i}. {need}: {count:,} casos ({count/len(self.df)*100:.1f}%)\n")

            # Insights sazonais
            season_impact = self.df.groupby('season')['total_human_impact'].sum().sort_values(ascending=False)
            f.write(f"\nüåÄ PADR√ïES SAZONAIS\n")
            f.write("-" * 50 + "\n")
            f.write(f"‚Ä¢ Esta√ß√£o mais cr√≠tica: {season_impact.index[0]}\n")
            f.write(f"‚Ä¢ Pessoas afetadas no pico: {season_impact.iloc[0]:,}\n")

            # Capacidades do sistema
            f.write(f"\nü§ñ CAPACIDADES DO SISTEMA\n")
            f.write("-" * 50 + "\n")
            f.write(f"‚Ä¢ Modelos ML Treinados: {len(self.ml_models)}\n")
            f.write(f"‚Ä¢ Features Analisadas: {self.df.shape[1]}\n")
            f.write(f"‚Ä¢ Mapa Interativo: Dispon√≠vel\n")
            f.write(f"‚Ä¢ Dashboard Completo: 12 visualiza√ß√µes\n")
            f.write(f"‚Ä¢ Predi√ß√µes: Operacional\n")

            # Recomenda√ß√µes estrat√©gicas
            f.write(f"\nüìã RECOMENDA√á√ïES ESTRAT√âGICAS\n")
            f.write("-" * 50 + "\n")
            f.write(f"1. Priorizar regi√£o {region_needs.index[0]} com √≠ndice {region_needs.iloc[0]:.1f}\n")
            f.write(f"2. Focar recursos no estado {state_impact.index[0]}\n")
            f.write(f"3. Preparar para pico sazonal no {season_impact.index[0]}\n")
            f.write(f"4. Estocar para necessidade principal: {need_counts.index[0]}\n")
            f.write(f"5. Monitorar {(self.df['need_index'] > 70).sum()} locais cr√≠ticos\n")

            # Conclus√µes
            f.write(f"\n‚úÖ CONCLUS√ïES\n")
            f.write("-" * 50 + "\n")
            f.write(f"O Sistema SolidarIA est√° operacional com capacidade de:\n")
            f.write(f"‚Ä¢ Analisar padr√µes clim√°ticos e socioecon√¥micos\n")
            f.write(f"‚Ä¢ Predizer necessidades com IA\n")
            f.write(f"‚Ä¢ Mapear geograficamente as demandas\n")
            f.write(f"‚Ä¢ Orientar estrat√©gias de doa√ß√£o\n")
            f.write(f"‚Ä¢ Otimizar log√≠stica humanit√°ria\n\n")

            f.write("="*80 + "\n")
            f.write("üåü Sistema SolidarIA - Transformando dados em a√ß√£o social\n")
            f.write("ü§ñ Intelig√™ncia Artificial a servi√ßo da solidariedade\n")

    def mostrar_resumo_final(self):
        """Mostra resumo final da execu√ß√£o"""
        print("\nüéä SISTEMA SOLIDARIA COMPLETO - RESUMO FINAL")
        print("="*70)

        print(f"üìä DADOS PROCESSADOS:")
        print(f"‚Ä¢ Registros analisados: {len(self.df):,}")
        print(f"‚Ä¢ Features criadas: {self.df.shape[1]}")
        print(f"‚Ä¢ Estados cobertos: {self.df['State'].nunique()}")
        print(f"‚Ä¢ Pessoas afetadas: {self.df['total_human_impact'].sum():,}")
        print(f"‚Ä¢ Per√≠odo analisado: {self.df['Date'].min().strftime('%Y')} - {self.df['Date'].max().strftime('%Y')}")

        print(f"\nü§ñ MACHINE LEARNING:")
        print(f"‚Ä¢ Modelos treinados: {len(self.ml_models)}")
        for model_name in self.ml_models.keys():
            print(f"  ‚úÖ {model_name}")

        print(f"\nüìà CAPACIDADES IMPLEMENTADAS:")
        capacidades = [
            "‚úÖ An√°lise explorat√≥ria autom√°tica",
            "‚úÖ Limpeza e prepara√ß√£o inteligente de dados",
            "‚úÖ Features avan√ßadas (temporais, clim√°ticas, geogr√°ficas)",
            "‚úÖ Modelos de Machine Learning para predi√ß√£o",
            "‚úÖ Dashboard completo com 12 visualiza√ß√µes",
            "‚úÖ Mapa interativo do Brasil (MANTIDO)",
            "‚úÖ Sistema de insights e recomenda√ß√µes",
            "‚úÖ Testes de cen√°rios realistas",
            "‚úÖ Exporta√ß√£o completa de resultados",
            "‚úÖ Relat√≥rios executivos autom√°ticos"
        ]

        for capacidade in capacidades:
            print(f"  {capacidade}")

        print(f"\nüéØ DESTAQUES DO SISTEMA:")
        region_needs = self.df.groupby('region')['need_index'].mean().sort_values(ascending=False)
        state_impact = self.df.groupby('State')['total_human_impact'].sum().sort_values(ascending=False)
        
        print(f"‚Ä¢ Regi√£o mais cr√≠tica: {region_needs.index[0]} ({region_needs.iloc[0]:.1f} pontos)")
        print(f"‚Ä¢ Estado priorit√°rio: {state_impact.index[0]} ({state_impact.iloc[0]:,} pessoas)")
        print(f"‚Ä¢ Necessidade principal: {self.df['priority_need_category'].mode().iloc[0]}")
        print(f"‚Ä¢ Casos cr√≠ticos: {(self.df['need_index'] > 70).sum()} locais")

        print(f"\nüìÅ ARQUIVOS GERADOS:")
        print("‚Ä¢ solidaria_results/dataset_processado_completo.csv")
        print("‚Ä¢ solidaria_results/estatisticas_regionais.csv")
        print("‚Ä¢ solidaria_results/ranking_necessidades_estados.csv")
        print("‚Ä¢ solidaria_results/relatorio_executivo_completo.txt")
        print("‚Ä¢ solidaria_results/metadata_sistema.json")

        print(f"\nüåü SISTEMA COMPLETAMENTE OPERACIONAL!")
        print("üáßüá∑ Mapa do Brasil integrado e funcional")
        print("ü§ñ IA treinada para predi√ß√µes inteligentes")
        print("üìä Dashboard completo com insights acion√°veis")
        print("üôè Pronto para transformar doa√ß√µes em impacto social!")

# ====================================================================
# FUN√á√ÉO PRINCIPAL PARA EXECUTAR TUDO
# ====================================================================

def executar_solidaria_unificado(dataset_path: str = None):
    """Fun√ß√£o principal que executa o sistema SolidarIA unificado completo"""

    print("üöÄ SISTEMA SOLIDARIA UNIFICADO - VERS√ÉO FINAL")
    print("ü§ñ IA + ML + Dashboard + Mapa Brasil + An√°lise Completa")
    print("="*70)
    
    if dataset_path:
        print(f"üìç Procurando dataset em: {dataset_path}")
    else:
        print("üìä Usando dados sint√©ticos para demonstra√ß√£o")
    
    print("‚ö° Executando an√°lise completa...")
    print("")

    # Inicializar sistema
    solidaria = SolidarIAComplete()

    # Executar sistema completo
    df_resultado = solidaria.executar_sistema_completo(dataset_path)

    if df_resultado is not None:
        print(f"\n‚úÖ EXECU√á√ÉO CONCLU√çDA COM SUCESSO!")
        print(f"üìä {len(df_resultado):,} registros processados")
        print(f"ü§ñ {len(solidaria.ml_models)} modelos de ML treinados")
        print(f"üó∫Ô∏è Mapa interativo do Brasil dispon√≠vel")
        print(f"üìÅ Resultados salvos em: ./solidaria_results/")
        print(f"‚è∞ Finalizado em: {datetime.now().strftime('%H:%M:%S')}")

        return solidaria, df_resultado
    else:
        print("‚ùå Falha na execu√ß√£o do sistema")
        return None, None

# ====================================================================
# FUN√á√ÉO DE DEMONSTRA√á√ÉO R√ÅPIDA
# ====================================================================

def demo_solidaria_rapido():
    """Demonstra√ß√£o r√°pida do sistema para apresenta√ß√µes"""
    
    print("üåü DEMO R√ÅPIDO - SISTEMA SOLIDARIA")
    print("="*50)
    
    # Executar vers√£o completa
    sistema, dados = executar_solidaria_unificado()
    
    if sistema is not None:
        print("\nüéØ FAZENDO PREDI√á√ÉO DE EXEMPLO:")
        print("-" * 40)
        
        # Teste r√°pido de predi√ß√£o
        resultado = sistema.fazer_predicao({
            'State': 'SP',
            'max_temperature': 38,
            'min_temperature': 24,
            'Population': 2000000,
            'month': 2,
            'disaster_category': 'Incendio'
        })
        
        print(f"üí° Necessidade: {resultado['necessidade']}")
        print(f"üéØ Confian√ßa: {resultado['confianca']:.1%}")
        print(f"üë• Impacto: {resultado['impacto_estimado']:,} pessoas")
        print(f"‚ö†Ô∏è Prioridade: {resultado['prioridade']}")
        
        print(f"\nüìã Recomenda√ß√µes:")
        for i, rec in enumerate(resultado['recomendacoes'][:3], 1):
            print(f"  {i}. {rec}")
            
        print("\nüéä DEMO CONCLU√çDO! Sistema operacional.")
        return sistema, dados
    
    return None, None

# ====================================================================
# EXECUTAR AUTOMATICAMENTE SE CHAMADO DIRETAMENTE
# ====================================================================

if __name__ == "__main__":
    """Execu√ß√£o autom√°tica quando o script for executado"""

    print("üåü SISTEMA SOLIDARIA UNIFICADO - INICIANDO")
    print("üìö Para usar na sua tese, execute este c√≥digo!")
    print("")

    # Executar sistema completo
    sistema, dados = executar_solidaria_unificado()

    if sistema is not None:
        print("\nüéä SISTEMA PRONTO PARA A TESE!")
        print("üìä Todas as an√°lises foram geradas")
        print("üó∫Ô∏è Mapa do Brasil est√° funcionando")
        print("ü§ñ Modelos ML est√£o treinados")
        print("üìÅ Arquivos exportados em 'solidaria_results'")
        print("üåü SolidarIA operacional!")
    else:
        print("\n‚ö†Ô∏è Houve problema na execu√ß√£o")
        print("üîß Verifique as depend√™ncias")

# ====================================================================
# EXEMPLOS DE USO PARA A TESE
# ====================================================================

"""
EXEMPLOS DE USO PARA SUA TESE:

1. EXECU√á√ÉO B√ÅSICA:
   sistema, dados = executar_solidaria_unificado()

2. COM DATASET PR√ìPRIO:
   sistema, dados = executar_solidaria_unificado('/caminho/para/seu/dataset.csv')

3. DEMO R√ÅPIDO:
   sistema, dados = demo_solidaria_rapido()

4. PREDI√á√ÉO PERSONALIZADA:
   resultado = sistema.fazer_predicao({
       'State': 'RJ',
       'max_temperature': 40,
       'min_temperature': 30,
       'Population': 1500000,
       'month': 1,
       'disaster_category': 'Inundacao'
   })

5. ACESSAR DADOS PROCESSADOS:
   print(dados.head())
   print(dados.columns.tolist())

CARACTER√çSTICAS PRINCIPAIS:
‚úÖ An√°lise explorat√≥ria autom√°tica
‚úÖ Machine Learning integrado
‚úÖ Mapa interativo do Brasil (MANTIDO)
‚úÖ Dashboard com 12 visualiza√ß√µes
‚úÖ Sistema de predi√ß√µes inteligentes
‚úÖ Exporta√ß√£o completa de resultados
‚úÖ Relat√≥rios executivos autom√°ticos
‚úÖ Dados sint√©ticos realistas para testes
‚úÖ Compat√≠vel com datasets reais

ARQUIVOS GERADOS:
- dataset_processado_completo.csv
- estatisticas_regionais.csv
- ranking_necessidades_estados.csv
- relatorio_executivo_completo.txt
- metadata_sistema.json

O sistema est√° pronto para uso acad√™mico e demonstra√ß√µes!
"""
